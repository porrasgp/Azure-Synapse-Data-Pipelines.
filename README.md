## title: "ğŸš€ Arquitectura de Datos en Azure con Synapse Analytics ğŸŒŸ"

Â¡Bienvenid@ a este repositorio! AquÃ­ encontrarÃ¡s tres laboratorios prÃ¡cticos para construir una **arquitectura de datos moderna** en Microsoft Azure. AprenderÃ¡s a crear **pipelines de datos** usando servicios como **Azure Data Factory**, **Azure Data Lake Storage Gen2**, **Azure Synapse Analytics** y mÃ¡s. ğŸ‰

## ğŸ“š Resumen de los Laboratorios

- **Laboratorio I** ğŸ› ï¸: Configura los cimientos de tu entorno Azure: grupo de recursos, cuenta de almacenamiento, Data Factory y Synapse Analytics.
- **Laboratorio II** ğŸ“¥: Crea un pipeline en Azure Data Factory para ingerir datos desde la *LandingZone* a la capa *Bronze*. Â¡Perfecto para procesos ETL! ğŸ”„
- **Laboratorio III** ğŸ“Š: Transforma datos con Spark Pools y construye una base de datos SQL serverless en Synapse para anÃ¡lisis avanzados. âœ¨

## ğŸ“‹ Prerrequisitos

- ğŸŒ SuscripciÃ³n activa de **Microsoft Azure** (recomendamos *Azure for Students*).
- ğŸ”‘ Acceso al **Azure Portal** y **Synapse Studio**.
- ğŸ“‚ Archivos de datos del curso (reemplaza los placeholders en `/Data`).
- ğŸ§  Conocimientos bÃ¡sicos de ETL/ELT y herramientas de Azure.

## ğŸ› ï¸ Estructura del Repositorio

- **Labs/** ğŸ“„: PDFs de los laboratorios (`Laboratorio_I.pdf`, `Laboratorio_II.pdf`, `Laboratorio_III.pdf`).
- **Scripts/** ğŸ’»: Scripts SQL (`SQL_covid_worldwide.sql`, `SQL_best_recovery.sql`) y notebooks de Spark (`nbk_covid_BZ_to_SZ.ipynb`, `nbk_covid_SZ_to_GZ.ipynb`).
- **Data/** ğŸ“ˆ: Archivos de datos de ejemplo (`Athletes.csv`, `covid_worldwide_rc.csv`) o placeholders. ObtÃ©n los originales del aula virtual.
- **Pipelines/** ğŸ”—: Configuraciones de pipelines como `LZ_to_BZ_Athletes_pipeline.json` para Azure Data Factory.
- **Docs/** ğŸ“–:
  - `setup_guide.md`: GuÃ­a para configurar tu entorno Azure.
  - `prerequisites.md`: Lista de requisitos para empezar.
  - `troubleshooting.md`: Soluciones a problemas comunes, como errores con el proveedor Microsoft.Synapse.

## ğŸš€ Instrucciones de ConfiguraciÃ³n

1. Sigue `Docs/setup_guide.md` para crear el grupo de recursos, cuenta de almacenamiento, Data Factory y Synapse Analytics. ğŸ—ï¸
2. Carga los archivos de datos al contenedor `datotokyoolympicsgps` en Azure Data Lake Storage Gen2. ğŸ“¤
3. Importa las configuraciones de pipelines desde `/Pipelines/` a Azure Data Factory. ğŸ”„
4. Ejecuta los notebooks y scripts SQL en Synapse Studio segÃºn las instrucciones de los laboratorios. ğŸ’¾

## ğŸƒâ€â™‚ï¸ CÃ³mo Ejecutar los Pipelines

- **Lab I** ğŸ› ï¸: Configura los recursos base y verifica el acceso a Synapse Studio.
- **Lab II** ğŸ“¥: Usa Azure Data Factory para mover datos de `LandingZone` a `Bronze`. Importa `LZ_to_BZ_Athletes_pipeline.json` o sigue el PDF.
- **Lab III** ğŸ“Š: Transforma datos (Bronze â†’ Silver â†’ Gold) con Spark y crea bases de datos SQL serverless.

## ğŸ¤ Contribuciones

Â¡Tu feedback es bienvenido! Crea un *issue* o envÃ­a un *pull request* para mejorar este repositorio. ğŸ’¡

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la [Licencia MIT](LICENSE). âœ…
